{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Read the dataset from previous days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "validDf = pd.read_csv(\"../data/valid_dataset_minimal_day1_2.csv\")\n",
    "campaigns = validDf[\"Campaign\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modeling the dataset for predictions (linear assumptions - baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Split into train and validation set (data is already valid, so no weird entries with no cost or no revenue/sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campaign: AW - Accessories. Df: (2266, 7). Useful data: (1283, 4). Train: (1026, 4). Validation: (257, 4)\n",
      "Campaign: AW - Bags. Df: (763, 7). Useful data: (236, 4). Train: (188, 4). Validation: (48, 4)\n",
      "Campaign: AW - Google Brand. Df: (970, 7). Useful data: (489, 4). Train: (391, 4). Validation: (98, 4)\n",
      "Campaign: AW - Office. Df: (613, 7). Useful data: (184, 4). Train: (147, 4). Validation: (37, 4)\n",
      "Campaign: AW - YouTube. Df: (486, 7). Useful data: (194, 4). Train: (155, 4). Validation: (39, 4)\n",
      "Campaign: AW - Apparel. Df: (2111, 7). Useful data: (824, 4). Train: (659, 4). Validation: (165, 4)\n",
      "Campaign: All Products. Df: (1583, 7). Useful data: (284, 4). Train: (227, 4). Validation: (57, 4)\n",
      "Campaign: AW - Dynamic Search Ads Whole Site. Df: (2335, 7). Useful data: (1070, 4). Train: (856, 4). Validation: (214, 4)\n"
     ]
    }
   ],
   "source": [
    "dfCampaigns = {k : validDf[validDf[\"Campaign\"] == k] for k in campaigns}\n",
    "trainData, valData = {}, {}\n",
    "relevantKeys = [\"Cost\", \"Revenue\", \"Sessions\"]\n",
    "for k in campaigns:\n",
    "    allData = dfCampaigns[k]\n",
    "#     print(allData.shape, allData.columns)\n",
    "    # The entry must have an associated cost and at least a revenue or a number of sessions\n",
    "    usefulData = allData.loc[(allData[\"Cost\"] * (allData[\"Revenue\"] + allData[\"Sessions\"])) > 0]\n",
    "    usefulData = usefulData.reset_index()[relevantKeys]\n",
    "    usefulData[\"Revenue (log)\"] = np.log(usefulData[\"Revenue\"] + 1)\n",
    "\n",
    "    np.random.seed(42)\n",
    "    perm = np.random.permutation(len(usefulData))\n",
    "    usefulData = usefulData.to_numpy()[perm]\n",
    "    nTrain = int(0.8 * len(usefulData))\n",
    "    \n",
    "    columns = [*relevantKeys, \"Revenue (log)\"]\n",
    "    trainData[k] = pd.DataFrame(usefulData[0 : nTrain], columns=columns)\n",
    "    valData[k] = pd.DataFrame(usefulData[nTrain :], columns=columns)\n",
    "    print(\"Campaign: %s. Df: %s. Useful data: %s. Train: %s. Validation: %s\" % \\\n",
    "          (k, str(allData.shape), str(usefulData.shape), str(trainData[k].shape), str(valData[k].shape)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Pure Statistical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatisticalModel:\n",
    "    def __init__(self):\n",
    "        # This model has just a single parameter, computed as the count between targets and inputs\n",
    "        self.param = np.nan\n",
    "        \n",
    "    def fit(self, x, t):\n",
    "        assert self.param != self.param\n",
    "        self.param = t.sum() / x.sum()\n",
    "    \n",
    "    def predict(self, x):\n",
    "        assert self.param == self.param\n",
    "        return x * self.param\n",
    "    \n",
    "def errorL1(y, t):\n",
    "    return np.abs(y - t).mean()\n",
    "\n",
    "def plot(model, valData, xKey, tKey):\n",
    "    validCampaigns = list(valData.keys())\n",
    "    ax = plt.subplots(len(validCampaigns), figsize=(5, 30))[1]\n",
    "    for i, k in enumerate(validCampaigns):\n",
    "        x = valData[k][xKey]\n",
    "        t = valData[k][tKey]\n",
    "        y = model[k].predict(x)\n",
    "        ax[i].scatter(x, y, label=\"%s Predicted\" % (tKey))\n",
    "        ax[i].scatter(x, t)\n",
    "        ax[i].set_title(k)\n",
    "        ax[i].legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Directly modeling f(Cost) = Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost x Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cost_revenue = {}\n",
    "predictions_cost_revenue = {}\n",
    "errors_cost_revenue = {}\n",
    "displayDf = pd.DataFrame()\n",
    "res_cost_revenue = []\n",
    "for k in validCampaigns:\n",
    "    model_cost_revenue[k] = StatisticalModel()\n",
    "    model_cost_revenue[k].fit(trainData[k][\"Cost\"], trainData[k][\"Revenue\"])\n",
    "    predictions_cost_revenue[k] = model_cost_revenue[k].predict(valData[k][\"Cost\"])\n",
    "    errors_cost_revenue[k] = errorL1(predictions_cost_revenue[k], valData[k][\"Revenue\"])\n",
    "    res_cost_revenue.append([k, trainData[k][\"Cost\"].sum(), trainData[k][\"Revenue\"].sum(), \\\n",
    "                model_cost_revenue[k].param, errors_cost_revenue[k]])\n",
    "\n",
    "displayDf = pd.DataFrame(res_cost_revenue, columns=[\"Campaign\", \"Cost\", \"Revenue\", \"Fit\", \"Error (L1)\"])\n",
    "display(displayDf)\n",
    "print(\"Mean error:\", displayDf[\"Error (L1)\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_cost_revenue, valData, \"Cost\", \"Revenue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Split in two models:\n",
    "We'll make the following assumption based on the graphs above. Let's assume that simply predicting f(Cost)=Revenue is too ambigue and let's assume that we can make a statistical analysis based on the number of sessions and the obtained revenue. \n",
    "\n",
    "Basically, the idea is that, the more sessions we have, the more revenue we'll have (second column of plots above), so we can make a linear assumption of Revenue ~= f(Sessions) for each campaign.\n",
    "\n",
    "Then, based on the data, we also see a strong correlation (column 1) between money invested (Cost) and the number of sessions. Thus, we can model Revenue ~= f(Sessions) = ct(Campaign) * #Sessions and Sessions ~= g(Cost), where g is a learned model. Thus, we could model the Revenue (of a Campaign) as Sessions ~= f(g(Cost)) = ct(Campaign) * g(Cost), where ct(Campaign) is a statistical constant, based on the number of revenue divided by number of sessions, for each Campaign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Cost x Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cost_sessions = {}\n",
    "predictions_cost_sessions = {}\n",
    "errors_cost_sessions = {}\n",
    "displayDf = pd.DataFrame()\n",
    "res_cost_sessions = []\n",
    "for k in validCampaigns:\n",
    "    model_cost_sessions[k] = StatisticalModel()\n",
    "    model_cost_sessions[k].fit(trainData[k][\"Cost\"], trainData[k][\"Sessions\"])\n",
    "    predictions_cost_sessions[k] = model_cost_sessions[k].predict(valData[k][\"Cost\"])\n",
    "    errors_cost_sessions[k] = errorL1(predictions_cost_sessions[k], valData[k][\"Sessions\"])\n",
    "    res_cost_sessions.append([k, trainData[k][\"Cost\"].sum(), trainData[k][\"Sessions\"].sum(), \\\n",
    "                model_cost_sessions[k].param, errors_cost_sessions[k]])\n",
    "\n",
    "displayDf = pd.DataFrame(res_cost_sessions, columns=[\"Campaign\", \"Cost\", \"Sessions\", \"Fit\", \"Error (L1)\"])\n",
    "display(displayDf)\n",
    "print(\"Mean error:\", displayDf[\"Error (L1)\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the results for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_cost_sessions, valData, \"Cost\", \"Sessions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Sessions x Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sessions_revenue = {}\n",
    "predictions_sessions_revenue = {}\n",
    "errors_sessions_revenue = {}\n",
    "displayDf = pd.DataFrame()\n",
    "res_sessions_revenue = []\n",
    "for k in validCampaigns:\n",
    "    model_sessions_revenue[k] = StatisticalModel()\n",
    "    model_sessions_revenue[k].fit(trainData[k][\"Sessions\"], trainData[k][\"Revenue\"])\n",
    "    predictions_sessions_revenue[k] = model_sessions_revenue[k].predict(valData[k][\"Sessions\"])\n",
    "    errors_sessions_revenue[k] = errorL1(predictions_sessions_revenue[k], valData[k][\"Revenue\"])\n",
    "    res_sessions_revenue.append([k, trainData[k][\"Sessions\"].sum(), trainData[k][\"Revenue\"].sum(), \\\n",
    "                model_sessions_revenue[k].param, errors_sessions_revenue[k]])\n",
    "\n",
    "displayDf = pd.DataFrame(res_sessions_revenue, columns=[\"Campaign\", \"Sessions\", \"Revenue\", \"Fit\", \"Error (L1)\"])\n",
    "display(displayDf)\n",
    "print(\"Mean error:\", displayDf[\"Error (L1)\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_sessions_revenue, valData, \"Sessions\", \"Revenue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.3 Cost x Sessions + Sessions x Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayDf = pd.DataFrame()\n",
    "errors_cost_revenue = {}\n",
    "res_cost_revenue_combined = []\n",
    "\n",
    "class TwoModel(object):\n",
    "    def __init__(self, modelA, modelB):\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.modelA.predict(self.modelB.predict(x))\n",
    "models_cost_revenue = {k : TwoModel(model_cost_sessions[k], model_sessions_revenue[k]) for k in valData}\n",
    "\n",
    "for k in validCampaigns:\n",
    "    predictions_cost_revenue[k] = models_cost_revenue[k].predict(valData[k][\"Cost\"])\n",
    "    errors_cost_revenue[k] = errorL1(predictions_cost_revenue[k], valData[k][\"Revenue\"])\n",
    "    res_cost_revenue_combined.append([k, errors_cost_revenue[k]])\n",
    "\n",
    "displayDf = pd.DataFrame(res_cost_revenue_combined, columns=[\"Campaign\", \"Error (L1)\"])\n",
    "display(displayDf)\n",
    "print(\"Mean error:\", displayDf[\"Error (L1)\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(models_cost_revenue, valData, \"Cost\", \"Revenue\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
