{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Budget allocation proposal\n",
    "\n",
    "### Pseudo-Revenue, First-Revenue assumption\n",
    "### Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                     datetime64[ns]\n",
      "Source / Medium                  object\n",
      "Campaign                         object\n",
      "Device Category                  object\n",
      "Users                             int64\n",
      "Sessions                          int64\n",
      "Bounces                           int64\n",
      "Transactions                      int64\n",
      "Cost                            float64\n",
      "Revenue                         float64\n",
      "Product Detail Views              int64\n",
      "Product Adds To Cart              int64\n",
      "Product Checkouts                 int64\n",
      "Session Duration                 object\n",
      "Total Unique Searches             int64\n",
      "Pageviews                        object\n",
      "New Users                         int64\n",
      "Session Duration (s)            float64\n",
      "Medium                           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 5]\n",
    "\n",
    "validDf = pd.read_csv(\"../data/valid_dataset_minimal.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "campaigns = validDf[\"Campaign\"].unique()\n",
    "validDf[\"Date\"] = pd.to_datetime(validDf[\"Date\"])\n",
    "# print(validDf.head(10))\n",
    "print(validDf.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Dataset creation\n",
    "\n",
    "### 0.1 Bucketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campaign 'AW - Accessories' has 452 (Cost, Revenue) buckets. Pruning max revenue from 1523.180 to 806.975\n",
      "Campaign 'AW - Apparel' has 138 (Cost, Revenue) buckets. Pruning max revenue from 1623.750 to 132.623\n",
      "Campaign 'Remarketing' has 5 (Cost, Revenue) buckets. Below 20, skipping.\n",
      "Campaign 'AW - Dynamic Search Ads Whole Site' has 382 (Cost, Revenue) buckets. Pruning max revenue from 2224.430 to 828.886\n",
      "Campaign 'AW - Bags' has 52 (Cost, Revenue) buckets. Pruning max revenue from 284.580 to 184.789\n",
      "Campaign 'AW - Google Brand' has 56 (Cost, Revenue) buckets. Pruning max revenue from 627.490 to 145.900\n",
      "Campaign 'AW - Office' has 36 (Cost, Revenue) buckets. Pruning max revenue from 1857.000 to 170.745\n",
      "Campaign 'AW - YouTube' has 5 (Cost, Revenue) buckets. Below 20, skipping.\n",
      "Campaign 'AW - Drinkware' has 10 (Cost, Revenue) buckets. Below 20, skipping.\n",
      "Campaign 'AW - YouTube Brand' has 10 (Cost, Revenue) buckets. Below 20, skipping.\n",
      "Campaign 'All Products' has 109 (Cost, Revenue) buckets. Pruning max revenue from 324.200 to 138.108\n",
      "___________________________________\n",
      "Original df: (9651, 19). Training df: (8281, 20)\n"
     ]
    }
   ],
   "source": [
    "def getCampaignFirstRevenue(df):\n",
    "    df[\"Bucket Index\"] = 0\n",
    "    # This holds the indexes (starting from 0) in the df where we've got positive revenues\n",
    "    indexesR = df.loc[df[\"Revenue\"] > 0, \"Revenue\"].index.values\n",
    "    # The same, but shifted to the left with one value and starting with -1\n",
    "    indexesL = np.array([-1, *indexesR[0 : -1]])\n",
    "    nRows = len(indexesL)\n",
    "\n",
    "    bucketIndex = -1\n",
    "    for i in range(nRows):\n",
    "        l, r = indexesL[i], indexesR[i]\n",
    "        where = (df.index > l) & (df.index <= r)\n",
    "        items = df[where]\n",
    "        # This merges conseccutive buckets if some of them have sum of costs 0, as that'd be useless data\n",
    "        # Instead, we assume that multiple consecutive revenues must be merged together and divided to first\n",
    "        if items[\"Cost\"].sum() > 0:\n",
    "            bucketIndex += 1\n",
    "        df.loc[where, \"Bucket Index\"] = bucketIndex\n",
    "    \n",
    "    items = df[df.index > indexesR[-1]]\n",
    "    assert len(items) == 0\n",
    "    return df\n",
    "\n",
    "# Return a new column called \"bucket index\", which represents on what (Cost, Revenue) bucket each entry goes\n",
    "# This is unique for all campaigns, so bucket index == 1 for Campaign \"A\", is a different bucket from bucket\n",
    "#  index == 1 for Campaign \"B\". This column is used to train on the same logical data (Bucket, Revenue), and\n",
    "#  we don't get Costs from same bucket both in train and validation set.\n",
    "# Other assumptions (like weekly assumption) can update this indexes as they will to provide other logic of\n",
    "#  implementation for the dataset split.\n",
    "def getDataFirstRevenue(df):\n",
    "    newDf = pd.DataFrame(columns=df.columns)\n",
    "    campaigns = df[\"Campaign\"].unique()\n",
    "    for campaign in campaigns:\n",
    "        dfCampaign = df[df[\"Campaign\"] == campaign].reset_index(drop=True)\n",
    "        newDfCampaign = getCampaignFirstRevenue(dfCampaign)\n",
    "        numBuckets = len(newDfCampaign[\"Bucket Index\"].unique())\n",
    "        print(\"Campaign '%s' has %d (Cost, Revenue) buckets.\" % (campaign, numBuckets), end=\"\")\n",
    "        if numBuckets < 20:\n",
    "            print(\" Below 20, skipping.\")\n",
    "            continue\n",
    "\n",
    "        revenues = newDfCampaign[\"Revenue\"]\n",
    "        # print(campaign, np.percentile(revenues, [0.1, 1, 10, 25, 50, 75, 90, 99, 99.5, 99.9, 100]))\n",
    "        # Clip the revenues to top 99.5%, to eliminate outliers.\n",
    "        Max = newDfCampaign[\"Revenue\"].max()\n",
    "        Top99_5 = np.percentile(newDfCampaign[\"Revenue\"], 99.5)\n",
    "        print(\" Pruning max revenue from %2.3f to %2.3f\" % (Max, Top99_5))\n",
    "        newDfCampaign[\"Revenue\"] = np.clip(newDfCampaign[\"Revenue\"], 0, Top99_5)\n",
    "        newDf = pd.concat([newDf, newDfCampaign], sort=False)      \n",
    "    return newDf\n",
    "\n",
    "firstRevenueDf = getDataFirstRevenue(validDf)\n",
    "print(\"___________________________________\")\n",
    "print(\"Original df: %s. Training df: %s\" % (validDf.shape, firstRevenueDf.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Pseudo-Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Linear Regression we've got the problem that the training data and the testing data is not from the same distribution.\n",
    "\n",
    "Basically, the problem is that we are training on Data: $X=\\sum(Costs)$ and Labels: $t=Revenue$, however, when we are using the model, we are generating from the distribution Data: $X=Cost$, PseudoRevenue: $y=f(X)$.\n",
    "\n",
    "The problem can be the simplest explained as: $a * f(x_1 + x_2) + b \\neq [a * f(x_1) + b] + [a * f(x_2) + b] $.\n",
    "\n",
    "However, we can always pre-split our data in first-revenue assumption AND linear time assumption (see proposal), basically instead of having $X=\\sum_n(Costs)$, $t=Revenue$, we can have $X=[Cost_1, ..., Cost_n]$, $t=[\\frac{Cost_1}{Revenue}, ..., \\frac{Cost_n}{Revenue}]$.\n",
    "\n",
    "The second nuance here is that we've got our data split in buckets of $(Cost, Revenue)$. Thus, what we do instead is for each bucket:\n",
    "\n",
    "$Cost_{B} = [Cost_1, ..., Cost_n]$ and $Revenue_{B} = [Revenue_1, ..., Revenue_m]$. We sum the revenues and the costs independently, to get $C_{\\Sigma B} = \\sum_{i}^{n}Cost_i$ and $R_{\\Sigma B} = \\sum_{i}^{m}Revenue_i$. We get the bucket's constant $\\alpha_B = \\frac{R_{\\Sigma B}}{C_{\\Sigma B}}$\n",
    "\n",
    "For statistical model, we had a dataset constant, which was the model's only parameter. Here, we get a bucket constant, which we use to create the pseudo revenue, by multiplying each cost: $Pseudo-Revenue_{B} = [Cost_1 * \\alpha_B, ..., Cost_n * \\alpha_B]$\n",
    "\n",
    "If we were to not use a linear time assumption, we'd have a non-linear ponder $C_{\\Sigma B} = \\sum_{i}^{n}(Cost_i * w_{i,n})$ where $w_{i, n}$ is somehow dependant on current timestamp (i) and final timestamp until last time of this bucket (n). This can be done using a separate model or some other way of detecting it. However, we'll just use a constant $w=1$ and assume all costs are identical to generating the next revenue.\n",
    "\n",
    "**Example:**\n",
    "Let a bucket be: $Cost_B=[0, 0, 50, 20, 0, 15]$, $Revenue_B=[30, 100]$. This means that the first revenue (30) was generated by the first two costs alone, so we merged the next bucket as well.\n",
    "\n",
    "We'll sum them, getting $C_{\\Sigma B}=85$ and $R_{\\Sigma B}=130$. Then, the bucket constant is: $\\alpha_B=130/85=1.529$.\n",
    "\n",
    "Then, our pseudo-revenues will be: $Pseudo-Revenue_{B} = [0*\\alpha_B, 0*\\alpha_B, 50*\\alpha_B, 20*\\alpha_B, 0*\\alpha_B, 15*\\alpha_B] = [0, 0, 76.45, 30.58, 0, 22.935]$.\n",
    "\n",
    "These are the values we'll predict for this bucket in our Regressions. We can see that summing them, we get $129.965$, which is almost $130$, the error being caused by truncations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    sumCost = x[\"Cost\"].sum()\n",
    "    sumRevenue = x[\"Revenue\"].sum()\n",
    "    bucketConstant = sumRevenue / sumCost\n",
    "    return bucketConstant\n",
    "\n",
    "def getPseudoRevenues(df):\n",
    "    df = df.copy()\n",
    "    dfGB = df.groupby([\"Campaign\", \"Bucket Index\"]).apply(lambda x : pd.Series({\n",
    "        \"Bucket Constant\" : f(x)\n",
    "    })).reset_index()\n",
    "    df = pd.merge(df, dfGB, on=[\"Campaign\", \"Bucket Index\"])\n",
    "    df[\"Pseudo Revenue\"] = df[\"Cost\"] * df[\"Bucket Constant\"]\n",
    "    return df\n",
    "\n",
    "trainDf = getPseudoRevenues(firstRevenueDf)\n",
    "trainDf[\"Bucket Index\"] = trainDf[\"Bucket Index\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Get Dataset statistics: Mins/Maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Campaign</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Session Duration (s)</th>\n",
       "      <th>Bucket Index</th>\n",
       "      <th>Bucket Constant</th>\n",
       "      <th>Pseudo Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AW - Accessories</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037720</td>\n",
       "      <td>0.000532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AW - Apparel</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017278</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AW - Bags</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069662</td>\n",
       "      <td>0.000697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AW - Dynamic Search Ads Whole Site</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029557</td>\n",
       "      <td>0.003863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AW - Google Brand</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033009</td>\n",
       "      <td>0.000330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AW - Office</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.377298</td>\n",
       "      <td>0.003773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>All Products</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.583503</td>\n",
       "      <td>0.010041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Campaign  Cost  Revenue  Session Duration (s)  \\\n",
       "0                    AW - Accessories  0.01      0.0                   0.0   \n",
       "1                        AW - Apparel  0.01      0.0                   0.0   \n",
       "2                           AW - Bags  0.01      0.0                   0.0   \n",
       "3  AW - Dynamic Search Ads Whole Site  0.01      0.0                   0.0   \n",
       "4                   AW - Google Brand  0.01      0.0                   0.0   \n",
       "5                         AW - Office  0.01      0.0                   0.0   \n",
       "6                        All Products  0.01      0.0                   0.0   \n",
       "\n",
       "   Bucket Index  Bucket Constant  Pseudo Revenue  \n",
       "0             0         0.037720        0.000532  \n",
       "1             0         0.017278        0.000173  \n",
       "2             0         0.069662        0.000697  \n",
       "3             0         0.029557        0.003863  \n",
       "4             0         0.033009        0.000330  \n",
       "5             0         0.377298        0.003773  \n",
       "6             0         0.583503        0.010041  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Campaign</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Session Duration (s)</th>\n",
       "      <th>Bucket Index</th>\n",
       "      <th>Bucket Constant</th>\n",
       "      <th>Pseudo Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AW - Accessories</td>\n",
       "      <td>74.04</td>\n",
       "      <td>806.97485</td>\n",
       "      <td>215881.0</td>\n",
       "      <td>451</td>\n",
       "      <td>1721.739130</td>\n",
       "      <td>698.189290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AW - Apparel</td>\n",
       "      <td>45.38</td>\n",
       "      <td>132.62345</td>\n",
       "      <td>215100.0</td>\n",
       "      <td>137</td>\n",
       "      <td>2059.000000</td>\n",
       "      <td>132.623450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AW - Bags</td>\n",
       "      <td>35.76</td>\n",
       "      <td>184.78880</td>\n",
       "      <td>214020.0</td>\n",
       "      <td>51</td>\n",
       "      <td>112.769231</td>\n",
       "      <td>184.788800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AW - Dynamic Search Ads Whole Site</td>\n",
       "      <td>54.57</td>\n",
       "      <td>828.88560</td>\n",
       "      <td>215940.0</td>\n",
       "      <td>381</td>\n",
       "      <td>112.391137</td>\n",
       "      <td>770.796582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AW - Google Brand</td>\n",
       "      <td>35.17</td>\n",
       "      <td>145.90000</td>\n",
       "      <td>215880.0</td>\n",
       "      <td>55</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>144.408180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AW - Office</td>\n",
       "      <td>17.52</td>\n",
       "      <td>170.74500</td>\n",
       "      <td>215100.0</td>\n",
       "      <td>35</td>\n",
       "      <td>203.267857</td>\n",
       "      <td>170.745000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>All Products</td>\n",
       "      <td>9.02</td>\n",
       "      <td>138.10800</td>\n",
       "      <td>214080.0</td>\n",
       "      <td>108</td>\n",
       "      <td>860.500000</td>\n",
       "      <td>108.176744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Campaign   Cost    Revenue  Session Duration (s)  \\\n",
       "0                    AW - Accessories  74.04  806.97485              215881.0   \n",
       "1                        AW - Apparel  45.38  132.62345              215100.0   \n",
       "2                           AW - Bags  35.76  184.78880              214020.0   \n",
       "3  AW - Dynamic Search Ads Whole Site  54.57  828.88560              215940.0   \n",
       "4                   AW - Google Brand  35.17  145.90000              215880.0   \n",
       "5                         AW - Office  17.52  170.74500              215100.0   \n",
       "6                        All Products   9.02  138.10800              214080.0   \n",
       "\n",
       "   Bucket Index  Bucket Constant  Pseudo Revenue  \n",
       "0           451      1721.739130      698.189290  \n",
       "1           137      2059.000000      132.623450  \n",
       "2            51       112.769231      184.788800  \n",
       "3           381       112.391137      770.796582  \n",
       "4            55       134.000000      144.408180  \n",
       "5            35       203.267857      170.745000  \n",
       "6           108       860.500000      108.176744  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getMinMax(df):\n",
    "    numericDf = df.select_dtypes(include=[np.number])\n",
    "    numericDf = numericDf.join(df[\"Campaign\"])\n",
    "    Mins = numericDf.groupby(\"Campaign\").min().reset_index()\n",
    "    Maxs = numericDf.groupby(\"Campaign\").max().reset_index()\n",
    "    return Mins, Maxs\n",
    "\n",
    "Mins, Maxs = getMinMax(trainDf)\n",
    "display(Mins)\n",
    "display(Maxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear Regression (no extra features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ipynb.fs.defs.nb3 import KFold\n",
    "import torch as tr\n",
    "import torch.nn as nn\n",
    "\n",
    "tr.backends.cudnn.deterministic = True\n",
    "tr.backends.cudnn.benchmark = False\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, numFeatures, useBias=True):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.useBias = useBias\n",
    "        self.numFeatures = numFeatures + int(self.useBias)\n",
    "        tr.manual_seed(42)\n",
    "        self.W = tr.randn(self.numFeatures, 1).requires_grad_(True)\n",
    "        self.trained = False\n",
    "\n",
    "    def prepare(self, X, t):\n",
    "        assert not self.trained\n",
    "        assert len(X.shape) == 2 and X.shape[-1] == self.numFeatures - self.useBias\n",
    "#         assert X.min() >= 0 and X.max() <= 1\n",
    "        tr.manual_seed(42)\n",
    "        self.W = tr.randn(self.numFeatures, 1).requires_grad_(True)\n",
    "        \n",
    "        X = X.astype(np.float32)\n",
    "        t = t.astype(np.float32)\n",
    "        \n",
    "        # Add bias\n",
    "        if self.useBias:\n",
    "            X = np.append(X, np.ones((len(X), 1), dtype=np.float32), axis=-1)\n",
    "        X = tr.from_numpy(X)\n",
    "        t = tr.from_numpy(t).unsqueeze(dim=-1)\n",
    "        return X, t\n",
    "    \n",
    "    def fit(self, X, t):\n",
    "        return self.fit_iter(X, t)\n",
    "        # TODO\n",
    "#         X, t = self.prepare(X, t)\n",
    "#         A = (X * t).mean(dim=0)\n",
    "#         B = (X**2).mean(dim=0)\n",
    "#         self.W = (A / B).detach().unsqueeze(dim=-1)\n",
    "    \n",
    "    def fit_iter(self, X, t, numIterations=1, lr=0.001):\n",
    "        X, t = self.prepare(X, t)\n",
    "        for i in range(numIterations):\n",
    "            L = self.criterion(X, t)\n",
    "            L.backward()\n",
    "            self.W.data -= lr * self.W.grad\n",
    "            self.W.grad *= 0\n",
    "        self.trained = True\n",
    "\n",
    "    def criterion(self, X, t):\n",
    "        y = tr.mm(X, self.W)\n",
    "        L = (y - t)**2\n",
    "        L = L.mean() + ((self.W)**2).mean()\n",
    "        return L\n",
    "        \n",
    "    def predict(self, X):\n",
    "#         assert self.trained\n",
    "        X = X.astype(np.float32)\n",
    "        if self.useBias:\n",
    "            X = np.append(X, np.ones((len(X), 1), dtype=np.float32), axis=-1)\n",
    "        X = tr.from_numpy(X)\n",
    "        y = tr.mm(X, self.W)\n",
    "        return y.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorL1(y, t):\n",
    "    return np.abs(y - t).mean()\n",
    "\n",
    "def trainModelLR(X, t, errorFn, Mappings, modelType, numSplits=5, randomState=42):\n",
    "    kf = KFold(numSplits=numSplits, randomState=randomState)\n",
    "    errors = []\n",
    "    Max = Mappings.max()\n",
    "    ix = np.arange(Max)\n",
    "    for trainIx, validationIx in kf.split(Max):\n",
    "        print(trainIx, )\n",
    "        model = modelType()\n",
    "        trainMap, valMap = ix[trainIx], ix[validationIx]\n",
    "        whereTrain = np.isin(Mappings, trainMap)\n",
    "        whereVal = np.isin(Mappings, valMap)\n",
    "        model.fit(X[whereTrain], t[whereTrain])\n",
    "        y = model.predict(X[whereVal])\n",
    "        errors.append(errorFn(y, t[whereVal]))\n",
    "\n",
    "    # We report the mean error on all K-fold splits for robustness\n",
    "    meanError = np.mean(errors)\n",
    "    \n",
    "    # Then, we retrain on all data, for best test/future predictions\n",
    "    model = modelType()\n",
    "    model.fit(X, t)\n",
    "    return model, meanError\n",
    "\n",
    "def trainAllCampaignsLR(df, modelType, features):\n",
    "    models, errors = {}, {}\n",
    "    validCampaigns = df[\"Campaign\"].unique()\n",
    "\n",
    "    for i, campaign in enumerate(validCampaigns):\n",
    "        where = df[\"Campaign\"] == campaign\n",
    "        X = df.loc[where, features].values\n",
    "        t = df.loc[where, [\"Revenue\"]].values\n",
    "        Mappings = df.loc[where, \"Bucket Index\"].values\n",
    "        model, error = trainModelLR(X, t, errorL1, Mappings, modelType)\n",
    "        models[campaign] = model\n",
    "        errors[campaign] = error\n",
    "    return models, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c70488f5d5dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Cost\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumFeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainAllCampaignsLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-adaa2eeb5634>\u001b[0m in \u001b[0;36mtrainAllCampaignsLR\u001b[0;34m(df, modelType, features)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Revenue\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mMappings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Bucket Index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainModelLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorL1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMappings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcampaign\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcampaign\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-adaa2eeb5634>\u001b[0m in \u001b[0;36mtrainModelLR\u001b[0;34m(X, t, errorFn, Mappings, modelType, numSplits, randomState)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrainModelLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMappings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumSplits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomState\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumSplits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumSplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomState\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandomState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mMax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMappings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KFold' is not defined"
     ]
    }
   ],
   "source": [
    "features = [\"Cost\"]\n",
    "LR = partial(LinearRegression, numFeatures=len(features))\n",
    "models, errors = trainAllCampaignsLR(trainDf, LR, features)\n",
    "\n",
    "for k in errors:\n",
    "    print(k, errors[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trainModelLR(X, t, Mappings, modelType, numSplits, randomState):\n",
    "#     kf = KFold(numSplits=numSplits, randomState=randomState)\n",
    "#     errors = []\n",
    "#     Max = Mappings.max()\n",
    "#     ix = np.arange(Max)\n",
    "#     for trainIx, validationIx in kf.split(Max):\n",
    "#         model = modelType()\n",
    "#         trainMap, valMap = ix[trainIx], ix[validationIx]\n",
    "#         whereTrain = np.isin(Mappings, trainMap)\n",
    "#         whereVal = np.isin(Mappings, valMap)\n",
    "#         model.fit(X[whereTrain], t[whereTrain])\n",
    "#         y = model.predict(X[whereVal])\n",
    "#         errors.append(errorL1(y, t[whereVal]))\n",
    "\n",
    "#     # We report the mean error on all K-fold splits for robustness\n",
    "#     meanError = np.mean(errors)\n",
    "    \n",
    "#     # Then, we retrain on all data, for best test/future predictions\n",
    "#     model = modelType()\n",
    "#     model.fit(X, t)\n",
    "#     return model, meanError\n",
    "\n",
    "# def trainAllCampaignsLR(df, X, t, modelType, columns, XXs, numSplits, randomState):\n",
    "#     models, errors = {}, {}\n",
    "#     validCampaigns = list(X.keys())\n",
    "#     df = df.copy()\n",
    "\n",
    "#     for i, campaign in enumerate(validCampaigns):\n",
    "#         thisT = np.clip(t[campaign], 0, np.percentile(t[campaign], XXs[campaign]))\n",
    "#         model, error = trainModelLR(X[campaign], thisT, Mappings[campaign], modelType, numSplits, randomState)\n",
    "#         dfCampaign = df[df[\"Campaign\"] == campaign]\n",
    "#         pseudo = model.predict(dfCampaign[columns].values)\n",
    "#         error = dfCampaign[\"Revenue\"].sum() - pseudo.sum()\n",
    "#         models[campaign] = model\n",
    "#         errors[campaign] = error\n",
    "#     return models, errors\n",
    "\n",
    "# def getOptimalThresholds(df, X, t, modelType, columns, numSplits, randomState):\n",
    "#     XXs = {}\n",
    "#     validCampaigns = list(X.keys())\n",
    "# #     Optimize threshold for all campaigns to remove outliers.\n",
    "#     for i, campaign in enumerate(validCampaigns):\n",
    "#         res = []\n",
    "#         for i in range(100):\n",
    "#             thisT = np.clip(t[campaign], 0, np.percentile(t[campaign], i))\n",
    "#             model, error = trainModelLR(X[campaign], thisT, Mappings[campaign], modelType, numSplits, randomState)\n",
    "#             dfCampaign = df[df[\"Campaign\"] == campaign].copy()\n",
    "#             dfCampaign[\"Pseudo Revenue\"] = model.predict(dfCampaign[columns])\n",
    "#             error = np.abs(dfCampaign[\"Revenue\"].sum() - dfCampaign[\"Pseudo Revenue\"].sum())\n",
    "#             res.append(error)\n",
    "#         XXs[campaign] = np.argmin(res)\n",
    "#     return XXs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, optimize threshold for each campaign, then use best one to get best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "LR = partial(LinearRegression, fit_intercept=False, normalize=True)\n",
    "XXs = getOptimalThresholds(validDf, XLinearRegression, tLinearRegression, LR, columns=[\"Cost\"], numSplits=5, randomState=42)\n",
    "print(XXs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRModels, LRErrors = trainAllCampaignsLR(validDf, XLinearRegression, tLinearRegression, LR, columns=[\"Cost\"], XXs=XXs, numSplits=5, randomState=42)\n",
    "display(pd.DataFrame([(x, y) for x, y in zip(LRErrors.keys(), LRErrors.values())], columns=[\"Campaign\", \"Best error (L1)\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.nb3 import createPseudoRevenues\n",
    "LRFinalDf = createPseudoRevenues(LRModels, validDf, features=[\"Cost\"])\n",
    "print(LRFinalDf.shape, LRFinalDf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.nb3 import plotRevenues\n",
    "plotRevenues(LRFinalDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.nb3 import scatterRevenues\n",
    "scatterRevenues(LRFinalDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.nb3 import getSummedPseudoRevenues\n",
    "LRFinalDf = getSummedPseudoRevenues(LRFinalDf, features=[\"Cost\"])\n",
    "print(LRFinalDf.shape, LRFinalDf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.nb3 import plotSummedRevenues\n",
    "plotSummedRevenues(LRFinalDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.nb3 import scatterSummedRevenues\n",
    "scatterSummedRevenues(LRFinalDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.nb3 import scatterErrorSummedRevenues\n",
    "scatterErrorSummedRevenues(LRFinalDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.nb3 import getOverallError\n",
    "LROverallError = getOverallError(LRFinalDf)\n",
    "display(LROverallError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.nb3 import plotFinalResults\n",
    "plotFinalResults(LRFinalDf, LROverallError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Linear regression with more features\n",
    "\n",
    "(TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Cost\", \"Device Category\"]\n",
    "validOneHotDf = pd.get_dummies(validDf[features].reset_index(drop=True))\n",
    "features = validOneHotDf.columns\n",
    "\n",
    "validOneHotDf = pd.merge(validDf[[\"Date\", \"Campaign\", \"Revenue\"]], validOneHotDf, left_index=True, right_index=True).reset_index(drop=True)\n",
    "XFeats, t = getDataFirstRevenue(validOneHotDf, features=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1.2 Convert columns to one-hot where possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XFeatsLR, tFeatsLR, Mappings = {}, {}, {}\n",
    "\n",
    "def getDataLR(X, t):\n",
    "    Mappings, XRes, tRes = [], [], []\n",
    "    N = len(X)\n",
    "    for i in range(N):\n",
    "        cost = X[i][:, 0]\n",
    "        XRes.extend(list(X[i]))\n",
    "        tRes.extend(list(t[i] / cost))\n",
    "        Mappings.extend([i] * len(X[i]))\n",
    "    return np.array(XRes), np.array(tRes).reshape((-1, 1)), np.array(Mappings)\n",
    "\n",
    "for k in X:\n",
    "    XFeatsNoDummy, tFeatsLR[k], Mappings[k] = getDataLR(XFeats[k], t[k])\n",
    "    \n",
    "    dummied = []\n",
    "    numFeatures = XFeatsNoDummy.shape[-1]\n",
    "    for i in range(numFeatures):\n",
    "        item = XFeatsNoDummy[:, i]\n",
    "        try:\n",
    "            _ = item.astype(np.float32)\n",
    "            item = item.reshape(-1, 1)\n",
    "        except Exception as e:\n",
    "            item = pd.get_dummies(item)\n",
    "        dummied.append(item)\n",
    "    XFeatsLR[k] = np.concatenate(dummied, axis=-1)\n",
    "    print(k, XFeatsLR[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = partial(LinearRegression, fit_intercept=True, normalize=True)\n",
    "XXs = getOptimalThresholds(validOneHotDf, XFeatsLR, tFeatsLR, LR, columns=features, numSplits=5, randomState=42)\n",
    "print(XXs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRModels, LRErrors = trainAllCampaignsLR(validOneHotDf, XFeatsLR, tFeatsLR, LR, columns=features, XXs=XXs, numSplits=5, randomState=42)\n",
    "display(pd.DataFrame([(x, y) for x, y in zip(LRErrors.keys(), LRErrors.values())], columns=[\"Campaign\", \"Best error (L1)\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRFinalDf = createPseudoRevenues(LRModels, validOneHotDf, features)\n",
    "print(LRFinalDf.shape, LRFinalDf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotRevenues(LRFinalDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterRevenues(LRFinalDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRFinalDf = getSummedPseudoRevenues(LRFinalDf, features=features)\n",
    "print(LRFinalDf.shape, LRFinalDf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSummedRevenues(LRFinalDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterSummedRevenues(LRFinalDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterErrorSummedRevenues(LRFinalDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LROverallError = getOverallError(LRFinalDf)\n",
    "display(LROverallError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFinalResults(LRFinalDf, LROverallError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
